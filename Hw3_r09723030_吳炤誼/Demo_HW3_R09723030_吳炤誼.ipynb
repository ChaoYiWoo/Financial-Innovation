{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "題目：Use LSTM & CNN model to classify customized candlestick pattern (at least 3 classes) <br/>\n",
    "1. Use LSTM model to classify customized candlestick pattern <br/>\n",
    "程式：candlestick_train_lstm_r09723030_吳炤誼.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 插入所需套件\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pickle\n",
    "import keras\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense, Activation, Conv2D, MaxPool2D, Dropout, Flatten\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pkl(pkl_name):\n",
    "    # 讀candlestick檔\n",
    "    with open(pkl_name, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data\n",
    "\n",
    "# lstm資料前處理\n",
    "def lstm_preprocess(x_train, x_test, y_train, y_test, n_step, n_input, n_classes):\n",
    "    # 把要訓練與測試的資料變成(n_step x n_input)\n",
    "    x_train = x_train.reshape(-1, n_step, n_input)\n",
    "    x_test = x_test.reshape(-1, n_step, n_input)\n",
    "    # 把數據變成32 bit\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    # (:normalize)除255提升模型辨識力\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    # 轉成特定的處理格式(one hot)\n",
    "    y_train = keras.utils.to_categorical(y_train, n_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, n_classes)\n",
    "    return (x_train, x_test, y_train, y_test)\n",
    "\n",
    "# lstm model\n",
    "def lstm_model(n_input, n_step, n_hidden, n_classes):\n",
    "    model = Sequential()\n",
    "    # 加入隱藏值\n",
    "    model.add(LSTM(n_hidden, batch_input_shape=(None, n_step, n_input), unroll=True))\n",
    "    # 輸出層\n",
    "    model.add(Dense(n_classes))\n",
    "    # 使用Activation中softmax fn將Y轉為機率值\n",
    "    model.add(Activation('softmax'))\n",
    "    return model\n",
    "\n",
    "# 訓練lstm model\n",
    "def train_lstm(model, x_train, y_train, x_test, y_test, \n",
    "        learning_rate, training_iters, batch_size):\n",
    "    # 學習速度(太大會在兩側波動，太小會浪費時間)\n",
    "    adam = Adam(lr=learning_rate)\n",
    "    model.summary()\n",
    "    # 選擇優化函數,損失函數,衡量方式\n",
    "    model.compile(optimizer=adam,\n",
    "        loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    # 訓練模型\n",
    "    model.fit(x_train, y_train,\n",
    "        batch_size=batch_size, epochs=training_iters,\n",
    "        verbose=1, validation_data=(x_test, y_test))\n",
    "\n",
    "def print_result(data, x_train, x_test, model):\n",
    "    # 得出預測值\n",
    "    train_pred = model.predict_classes(x_train)\n",
    "    test_pred = model.predict_classes(x_test)\n",
    "    # 實際值\n",
    "    train_label = data['train_label'][:, 0]\n",
    "    test_label = data['test_label'][:, 0]\n",
    "    # 比較兩者，以confusion_matrix呈現(9x9) 越集中在對角線，越準確\n",
    "    train_result_cm = confusion_matrix(train_label, train_pred, labels=range(9))\n",
    "    test_result_cm = confusion_matrix(test_label, test_pred, labels=range(9))\n",
    "    print(train_result_cm, '\\n'*2, test_result_cm)\n",
    "\n",
    "def mnist_lstm_main():\n",
    "    # 給機器學的參數\n",
    "    # adam學習速度預設為0.001\n",
    "    learning_rate = 0.005\n",
    "    #迭代次數\n",
    "    training_iters = 50\n",
    "    # 學習速度調至0.005&迭代50次得到比原本較高的準確率)\n",
    "    # 每次樣本數\n",
    "    batch_size = 128\n",
    "\n",
    "    # 模型參數(層、步數、隱藏值(特徵數)、分成幾類)\n",
    "    n_input = 40\n",
    "    n_step = 10\n",
    "    n_hidden = 256\n",
    "    n_classes = 10\n",
    "   \n",
    "    #讀取資料，進行資料前處理\n",
    "    data = load_pkl('C:/Users/ben82/ipython_notebook_workplace/label8_eurusd_10bar_1500_500_val200_gaf_culr.pkl')\n",
    "    x_train, y_train, x_test, y_test = data['train_gaf'], data['train_label'][:, 0], data['test_gaf'], data['test_label'][:, 0]\n",
    "    x_train, x_test, y_train, y_test = lstm_preprocess(x_train, x_test, y_train, y_test, n_step, n_input, n_classes)\n",
    "\n",
    "    #訓練lstm模型並印出結果\n",
    "    model = lstm_model(n_input, n_step, n_hidden, n_classes)\n",
    "    train_lstm(model, x_train, y_train, x_test, y_test, learning_rate, \n",
    "               training_iters, batch_size)\n",
    "    scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('LSTM test accuracy:', scores[1])\n",
    "    print_result(data, x_train, x_test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 256)               304128    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 306,698\n",
      "Trainable params: 306,698\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "118/118 [==============================] - 6s 39ms/step - loss: 2.0234 - accuracy: 0.2118 - val_loss: 1.5167 - val_accuracy: 0.3046\n",
      "Epoch 2/50\n",
      "118/118 [==============================] - 4s 32ms/step - loss: 1.4377 - accuracy: 0.3606 - val_loss: 1.1582 - val_accuracy: 0.5506\n",
      "Epoch 3/50\n",
      "118/118 [==============================] - 4s 33ms/step - loss: 1.1206 - accuracy: 0.5502 - val_loss: 1.1583 - val_accuracy: 0.5586\n",
      "Epoch 4/50\n",
      "118/118 [==============================] - 4s 37ms/step - loss: 0.8406 - accuracy: 0.6701 - val_loss: 0.6010 - val_accuracy: 0.7628\n",
      "Epoch 5/50\n",
      "118/118 [==============================] - 4s 36ms/step - loss: 0.6776 - accuracy: 0.7367 - val_loss: 0.6685 - val_accuracy: 0.7526\n",
      "Epoch 6/50\n",
      "118/118 [==============================] - 5s 39ms/step - loss: 0.6436 - accuracy: 0.7507 - val_loss: 0.6336 - val_accuracy: 0.7668\n",
      "Epoch 7/50\n",
      "118/118 [==============================] - 5s 40ms/step - loss: 0.6004 - accuracy: 0.7702 - val_loss: 0.6138 - val_accuracy: 0.7680\n",
      "Epoch 8/50\n",
      "118/118 [==============================] - 4s 35ms/step - loss: 0.5683 - accuracy: 0.7803 - val_loss: 0.4777 - val_accuracy: 0.8222\n",
      "Epoch 9/50\n",
      "118/118 [==============================] - 4s 35ms/step - loss: 0.5506 - accuracy: 0.7903 - val_loss: 0.4191 - val_accuracy: 0.8556\n",
      "Epoch 10/50\n",
      "118/118 [==============================] - 4s 36ms/step - loss: 0.5083 - accuracy: 0.8100 - val_loss: 0.5158 - val_accuracy: 0.8144\n",
      "Epoch 11/50\n",
      "118/118 [==============================] - 4s 33ms/step - loss: 0.5650 - accuracy: 0.7854 - val_loss: 0.4734 - val_accuracy: 0.8310\n",
      "Epoch 12/50\n",
      "118/118 [==============================] - 4s 32ms/step - loss: 0.5164 - accuracy: 0.7962 - val_loss: 0.5977 - val_accuracy: 0.7770\n",
      "Epoch 13/50\n",
      "118/118 [==============================] - 4s 34ms/step - loss: 0.5070 - accuracy: 0.8082 - val_loss: 0.5055 - val_accuracy: 0.8078\n",
      "Epoch 14/50\n",
      "118/118 [==============================] - 4s 31ms/step - loss: 0.4771 - accuracy: 0.8200 - val_loss: 0.4641 - val_accuracy: 0.8178\n",
      "Epoch 15/50\n",
      "118/118 [==============================] - 4s 31ms/step - loss: 0.4793 - accuracy: 0.8215 - val_loss: 0.5609 - val_accuracy: 0.7940\n",
      "Epoch 16/50\n",
      "118/118 [==============================] - 4s 31ms/step - loss: 0.4879 - accuracy: 0.8133 - val_loss: 0.5218 - val_accuracy: 0.8086\n",
      "Epoch 17/50\n",
      "118/118 [==============================] - 4s 34ms/step - loss: 0.4969 - accuracy: 0.8142 - val_loss: 0.4505 - val_accuracy: 0.8386\n",
      "Epoch 18/50\n",
      "118/118 [==============================] - 4s 34ms/step - loss: 0.5296 - accuracy: 0.8009 - val_loss: 0.4007 - val_accuracy: 0.8566\n",
      "Epoch 19/50\n",
      "118/118 [==============================] - 4s 32ms/step - loss: 0.4673 - accuracy: 0.8234 - val_loss: 0.5276 - val_accuracy: 0.7934\n",
      "Epoch 20/50\n",
      "118/118 [==============================] - 4s 33ms/step - loss: 0.5019 - accuracy: 0.8090 - val_loss: 0.4834 - val_accuracy: 0.8240\n",
      "Epoch 21/50\n",
      "118/118 [==============================] - 4s 32ms/step - loss: 0.4605 - accuracy: 0.8237 - val_loss: 0.3972 - val_accuracy: 0.8550\n",
      "Epoch 22/50\n",
      "118/118 [==============================] - 4s 32ms/step - loss: 0.5123 - accuracy: 0.8037 - val_loss: 0.4858 - val_accuracy: 0.8210\n",
      "Epoch 23/50\n",
      "118/118 [==============================] - 4s 31ms/step - loss: 0.4829 - accuracy: 0.8160 - val_loss: 0.4287 - val_accuracy: 0.8386\n",
      "Epoch 24/50\n",
      "118/118 [==============================] - 4s 34ms/step - loss: 0.4449 - accuracy: 0.8311 - val_loss: 0.3897 - val_accuracy: 0.8650\n",
      "Epoch 25/50\n",
      "118/118 [==============================] - 4s 33ms/step - loss: 0.4443 - accuracy: 0.8310 - val_loss: 0.3768 - val_accuracy: 0.8644\n",
      "Epoch 26/50\n",
      "118/118 [==============================] - 4s 31ms/step - loss: 0.4590 - accuracy: 0.8283 - val_loss: 0.6002 - val_accuracy: 0.7776\n",
      "Epoch 27/50\n",
      "118/118 [==============================] - 4s 31ms/step - loss: 0.5327 - accuracy: 0.7994 - val_loss: 0.3902 - val_accuracy: 0.8616\n",
      "Epoch 28/50\n",
      "118/118 [==============================] - 4s 32ms/step - loss: 0.4491 - accuracy: 0.8291 - val_loss: 0.5261 - val_accuracy: 0.7908\n",
      "Epoch 29/50\n",
      "118/118 [==============================] - 4s 32ms/step - loss: 0.4745 - accuracy: 0.8219 - val_loss: 0.3668 - val_accuracy: 0.8762\n",
      "Epoch 30/50\n",
      "118/118 [==============================] - 4s 35ms/step - loss: 0.4616 - accuracy: 0.8243 - val_loss: 0.4285 - val_accuracy: 0.8368\n",
      "Epoch 31/50\n",
      "118/118 [==============================] - 4s 34ms/step - loss: 0.4376 - accuracy: 0.8390 - val_loss: 0.4765 - val_accuracy: 0.8186\n",
      "Epoch 32/50\n",
      "118/118 [==============================] - 4s 34ms/step - loss: 0.4768 - accuracy: 0.8211 - val_loss: 0.3882 - val_accuracy: 0.8574\n",
      "Epoch 33/50\n",
      "118/118 [==============================] - 4s 32ms/step - loss: 0.4416 - accuracy: 0.8319 - val_loss: 0.4186 - val_accuracy: 0.8502\n",
      "Epoch 34/50\n",
      "118/118 [==============================] - 4s 33ms/step - loss: 0.4372 - accuracy: 0.8362 - val_loss: 0.4636 - val_accuracy: 0.8274\n",
      "Epoch 35/50\n",
      "118/118 [==============================] - 4s 33ms/step - loss: 0.4494 - accuracy: 0.8294 - val_loss: 0.4113 - val_accuracy: 0.8430\n",
      "Epoch 36/50\n",
      "118/118 [==============================] - 4s 32ms/step - loss: 0.4522 - accuracy: 0.8295 - val_loss: 0.4231 - val_accuracy: 0.8416\n",
      "Epoch 37/50\n",
      "118/118 [==============================] - 4s 32ms/step - loss: 0.4154 - accuracy: 0.8464 - val_loss: 0.4883 - val_accuracy: 0.8056\n",
      "Epoch 38/50\n",
      "118/118 [==============================] - 4s 32ms/step - loss: 0.4050 - accuracy: 0.8512 - val_loss: 0.3514 - val_accuracy: 0.8794\n",
      "Epoch 39/50\n",
      "118/118 [==============================] - 4s 32ms/step - loss: 0.4201 - accuracy: 0.8389 - val_loss: 0.5255 - val_accuracy: 0.8116\n",
      "Epoch 40/50\n",
      "118/118 [==============================] - 4s 33ms/step - loss: 0.4255 - accuracy: 0.8359 - val_loss: 0.4077 - val_accuracy: 0.8548\n",
      "Epoch 41/50\n",
      "118/118 [==============================] - 4s 35ms/step - loss: 0.4054 - accuracy: 0.8471 - val_loss: 0.4157 - val_accuracy: 0.8510\n",
      "Epoch 42/50\n",
      "118/118 [==============================] - 4s 31ms/step - loss: 0.4249 - accuracy: 0.8389 - val_loss: 0.4066 - val_accuracy: 0.8548\n",
      "Epoch 43/50\n",
      "118/118 [==============================] - 4s 33ms/step - loss: 0.4102 - accuracy: 0.8430 - val_loss: 0.4256 - val_accuracy: 0.8402\n",
      "Epoch 44/50\n",
      "118/118 [==============================] - 4s 34ms/step - loss: 0.4029 - accuracy: 0.8467 - val_loss: 0.4267 - val_accuracy: 0.8388\n",
      "Epoch 45/50\n",
      "118/118 [==============================] - 4s 33ms/step - loss: 0.4315 - accuracy: 0.8382 - val_loss: 0.4845 - val_accuracy: 0.8168\n",
      "Epoch 46/50\n",
      "118/118 [==============================] - 4s 34ms/step - loss: 0.4012 - accuracy: 0.8493 - val_loss: 0.3611 - val_accuracy: 0.8732\n",
      "Epoch 47/50\n",
      "118/118 [==============================] - 4s 34ms/step - loss: 0.4048 - accuracy: 0.8452 - val_loss: 0.3754 - val_accuracy: 0.8658\n",
      "Epoch 48/50\n",
      "118/118 [==============================] - 4s 34ms/step - loss: 0.3916 - accuracy: 0.8543 - val_loss: 0.4586 - val_accuracy: 0.8296\n",
      "Epoch 49/50\n",
      "118/118 [==============================] - 4s 34ms/step - loss: 0.4434 - accuracy: 0.8297 - val_loss: 0.3793 - val_accuracy: 0.8624\n",
      "Epoch 50/50\n",
      "118/118 [==============================] - 4s 35ms/step - loss: 0.3905 - accuracy: 0.8492 - val_loss: 0.4133 - val_accuracy: 0.8508\n",
      "LSTM test accuracy: 0.8507999777793884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ben82\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1992  138  103   98  155   80  250   66  118]\n",
      " [  94 1401    0    0    0    0    5    0    0]\n",
      " [  43    0 1290    0  165    0    0    0    2]\n",
      " [  34   92    0 1285    0    0    0   89    0]\n",
      " [  11    0    1    0 1152    0    0    0  336]\n",
      " [ 145    1    0    0    0 1346    3    5    0]\n",
      " [   4    1    0    0    2    0 1473    0   20]\n",
      " [  39    3    0  218    0   25    0 1215    0]\n",
      " [   9    0    0    0   56    0   35    0 1400]] \n",
      "\n",
      " [[675  39  42  29  52  25  75  24  39]\n",
      " [ 29 471   0   0   0   0   0   0   0]\n",
      " [ 10   0 438   0  52   0   0   0   0]\n",
      " [ 20  34   0 430   0   0   0  16   0]\n",
      " [  7   0   0   0 396   0   0   0  97]\n",
      " [ 66   0   0   0   0 434   0   0   0]\n",
      " [  2   0   0   0   0   0 492   0   6]\n",
      " [ 21   0   0  40   0   7   0 432   0]\n",
      " [  4   0   0   0   2   0   8   0 486]]\n"
     ]
    }
   ],
   "source": [
    "mnist_lstm_main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Use CNN model to classify customized candlestick pattern <br/>\n",
    "程式：candlestick_train_cnn_r09723030_吳炤誼.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 插入所需套件\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, Activation, MaxPool2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pkl(pkl_name):\n",
    "    # 讀取pkl檔\n",
    "    with open(pkl_name, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data\n",
    "\n",
    "# cnn model\n",
    "def get_cnn_model(params):\n",
    "    model = Sequential()\n",
    "    # 二維捲積層(用5x5去捲,輸出10x10),超過的部份補零(same fn),用忽略負值的方式(relu fn)計算\n",
    "    model.add(Conv2D(filters=32, kernel_size=(5,5), padding='same', activation='relu', input_shape=(10, 10, 4)))\n",
    "    # 再捲一次\n",
    "    model.add(Conv2D(filters=48, kernel_size=(5,5), padding='valid', activation='relu'))\n",
    "    # 攤平維度 \n",
    "    model.add(Flatten())\n",
    "    # 疊三層(前兩層以忽略負值的方式算,最後一層用機率的方式算)\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(84, activation='relu'))\n",
    "    model.add(Dense(9, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "# 訓練model\n",
    "def train_model(params, data):\n",
    "    model = get_cnn_model(params)\n",
    "    # 選擇優化函數,損失函數,衡量方式\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=params['optimizer'], metrics=['accuracy'])\n",
    "    hist = model.fit(x=data['train_gaf'], y=data['train_label_arr'],\n",
    "                     batch_size=params['batch_size'], epochs=params['epochs'], verbose=2)\n",
    "    return (model, hist)\n",
    "\n",
    "#印出結果\n",
    "def print_result(data, model):\n",
    "    # 得到訓練的值\n",
    "    train_pred = model.predict_classes(data['train_gaf'])\n",
    "    test_pred = model.predict_classes(data['test_gaf'])\n",
    "    # 實際值\n",
    "    train_label = data['train_label'][:, 0]\n",
    "    test_label = data['test_label'][:, 0]\n",
    "    # 比較兩者，以confusion_matrix呈現(9x9) 越集中在對角線，越準確\n",
    "    train_result_cm = confusion_matrix(train_label, train_pred, labels=range(9))\n",
    "    test_result_cm = confusion_matrix(test_label, test_pred, labels=range(9))\n",
    "    print(train_result_cm, '\\n'*2, test_result_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "469/469 - 4s - loss: 1.4971 - accuracy: 0.4589\n",
      "Epoch 2/20\n",
      "469/469 - 4s - loss: 0.7597 - accuracy: 0.7258\n",
      "Epoch 3/20\n",
      "469/469 - 4s - loss: 0.5951 - accuracy: 0.7861\n",
      "Epoch 4/20\n",
      "469/469 - 4s - loss: 0.5217 - accuracy: 0.8098\n",
      "Epoch 5/20\n",
      "469/469 - 4s - loss: 0.4846 - accuracy: 0.8256\n",
      "Epoch 6/20\n",
      "469/469 - 4s - loss: 0.4577 - accuracy: 0.8333\n",
      "Epoch 7/20\n",
      "469/469 - 4s - loss: 0.4398 - accuracy: 0.8395\n",
      "Epoch 8/20\n",
      "469/469 - 4s - loss: 0.4227 - accuracy: 0.8493\n",
      "Epoch 9/20\n",
      "469/469 - 4s - loss: 0.4067 - accuracy: 0.8537\n",
      "Epoch 10/20\n",
      "469/469 - 4s - loss: 0.3967 - accuracy: 0.8581\n",
      "Epoch 11/20\n",
      "469/469 - 4s - loss: 0.3836 - accuracy: 0.8613\n",
      "Epoch 12/20\n",
      "469/469 - 5s - loss: 0.3768 - accuracy: 0.8629\n",
      "Epoch 13/20\n",
      "469/469 - 4s - loss: 0.3675 - accuracy: 0.8640\n",
      "Epoch 14/20\n",
      "469/469 - 4s - loss: 0.3594 - accuracy: 0.8720\n",
      "Epoch 15/20\n",
      "469/469 - 4s - loss: 0.3519 - accuracy: 0.8722\n",
      "Epoch 16/20\n",
      "469/469 - 4s - loss: 0.3447 - accuracy: 0.8755\n",
      "Epoch 17/20\n",
      "469/469 - 4s - loss: 0.3371 - accuracy: 0.8791\n",
      "Epoch 18/20\n",
      "469/469 - 4s - loss: 0.3303 - accuracy: 0.8837\n",
      "Epoch 19/20\n",
      "469/469 - 4s - loss: 0.3240 - accuracy: 0.8851\n",
      "Epoch 20/20\n",
      "469/469 - 4s - loss: 0.3203 - accuracy: 0.8846\n",
      "CNN test accuracy: 0.8546000123023987\n",
      "[[2436   47   85   64   70   50   49  116   83]\n",
      " [  51 1447    0    2    0    0    0    0    0]\n",
      " [  55    0 1444    0    1    0    0    0    0]\n",
      " [  47    9    0 1106    0    0    0  338    0]\n",
      " [  60    0   35    0 1288    0    2    0  115]\n",
      " [ 115    0    0    0    0 1349    0   36    0]\n",
      " [ 118    1    1    0    2    0 1341    0   37]\n",
      " [  23    0    0   33    0    4    0 1440    0]\n",
      " [  42    0    3    0   94    0   15    0 1346]] \n",
      "\n",
      " [[781  20  42  22  29  22  15  39  30]\n",
      " [ 22 477   0   1   0   0   0   0   0]\n",
      " [ 15   0 485   0   0   0   0   0   0]\n",
      " [ 28  11   0 363   0   0   0  98   0]\n",
      " [ 39   0  21   0 386   0   0   0  54]\n",
      " [ 67   0   0   0   0 423   0  10   0]\n",
      " [ 69   0   1   0   0   0 422   0   8]\n",
      " [ 11   1   0   1   0   1   0 486   0]\n",
      " [ 17   0   0   0  27   0   6   0 450]]\n"
     ]
    }
   ],
   "source": [
    "    PARAMS = {}\n",
    "\n",
    "    PARAMS['pkl_name'] = 'C:/Users/ben82/ipython_notebook_workplace/label8_eurusd_10bar_1500_500_val200_gaf_culr.pkl'\n",
    "    # 分類\n",
    "    PARAMS['classes'] = 9\n",
    "    # 學習速度(設為0.005準確度提高)\n",
    "    PARAMS['lr'] = 0.005\n",
    "    # 迭代次數\n",
    "    PARAMS['epochs'] = 20\n",
    "    # 每次處理樣本數\n",
    "    PARAMS['batch_size'] = 32\n",
    "    #(設為0.005,20,32)準確度提高\n",
    "    PARAMS['optimizer'] = optimizers.SGD(lr=PARAMS['lr'])\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 讀檔\n",
    "    data = load_pkl(PARAMS['pkl_name'])\n",
    "    # train cnn model\n",
    "    model, hist = train_model(PARAMS, data)\n",
    "    # train & test result\n",
    "    scores = model.evaluate(data['test_gaf'], data['test_label_arr'], verbose=0)\n",
    "    print('CNN test accuracy:', scores[1])\n",
    "    print_result(data, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
