{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "題目<br/>\n",
    "Use LSTM & CNN model to classify MNIST dataset with at least 90%<br/>\n",
    "一、程式碼<br/>\n",
    "所有檔案: mnist_train_all_r09723030_吳炤誼.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Use LSTM & CNN model to classify MNIST <br/>\n",
    "  by mnist_train_all_r09723030_吳炤誼.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 插入所需套件\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import keras\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense, Activation, Conv2D, MaxPool2D, Dropout, Flatten\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm資料前處理\n",
    "def lstm_preprocess(x_train, x_test, y_train, y_test, n_step, n_input, n_classes):\n",
    "    # 把要訓練與測試的資料變成(n_step x n_input)\n",
    "    x_train = x_train.reshape(-1, n_step, n_input)\n",
    "    x_test = x_test.reshape(-1, n_step, n_input)\n",
    "    # 把數據變成32 bit\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    # (習慣:normalize)除255提升模型辨識力\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    # 轉成特定的處理格式(one hot)\n",
    "    y_train = keras.utils.to_categorical(y_train, n_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, n_classes)\n",
    "    return (x_train, x_test, y_train, y_test)\n",
    "\n",
    "# lstm model\n",
    "def lstm_model(n_input, n_step, n_hidden, n_classes):\n",
    "    model = Sequential()\n",
    "    # 加入隱藏值\n",
    "    model.add(LSTM(n_hidden, batch_input_shape=(None, n_step, n_input), unroll=True))\n",
    "    # 輸出層\n",
    "    model.add(Dense(n_classes))\n",
    "    # 使用softmax fn將Y轉為機率值\n",
    "    model.add(Activation('softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN nodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn資料前處理\n",
    "# 同lstm\n",
    "def cnn_preprocess(x_train, x_test, y_train, y_test):\n",
    "    x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "    x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    y_train = keras.utils.to_categorical(y_train, 10)\n",
    "    y_test = keras.utils.to_categorical(y_test, 10)\n",
    "    return (x_train, x_test, y_train, y_test)\n",
    "\n",
    "# cnn model\n",
    "def cnn_model():\n",
    "    model = Sequential()\n",
    "    # 二維捲積層(用5x5去捲,輸出28x28),超過的部份補零(same fn),用忽略負值的方式(relu fn)計算\n",
    "    model.add(Conv2D(filters=32, kernel_size=(5,5), padding='same', activation='relu', input_shape=(28, 28, 1)))\n",
    "    # 池化層(取最大值來簡化)\n",
    "    model.add(MaxPool2D(strides=2))\n",
    "    # 再捲一次 & 池化\n",
    "    model.add(Conv2D(filters=48, kernel_size=(5,5), padding='valid', activation='relu'))\n",
    "    model.add(MaxPool2D(strides=2))\n",
    "    # 攤平維度 \n",
    "    model.add(Flatten())\n",
    "    # 疊三層\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(84, activation='relu'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "訓練&印出結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainning(model, x_train, y_train, x_test, y_test, \n",
    "              learning_rate, training_iters, batch_size):\n",
    "    # 學習速度(太大會一直波動，太小會浪費時間)\n",
    "    adam = Adam(lr=learning_rate)\n",
    "    model.summary()\n",
    "    # 選擇優化函數,損失函數,衡量方式\n",
    "    model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    # 訓練模型\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size, epochs=training_iters,\n",
    "              verbose=1, validation_data=(x_test, y_test))\n",
    "\n",
    "def print_confusion_result(x_train, x_test, y_train, y_test, model):\n",
    "    # 得出預測值\n",
    "    train_pred = model.predict_classes(x_train)\n",
    "    test_pred = model.predict_classes(x_test)\n",
    "    \n",
    "    # 實際值\n",
    "    train_label = y_train\n",
    "    test_label =  y_test\n",
    "    \n",
    "    # 比較兩者，以confusion_matrix呈現(10x10) 越集中在對角線，越準確\n",
    "    train_result_cm = confusion_matrix(train_label, train_pred, labels=range(10))\n",
    "    test_result_cm = confusion_matrix(test_label, test_pred, labels=range(10))\n",
    "    print(train_result_cm, '\\n'*2, test_result_cm)\n",
    "\n",
    "def mnist_lstm_main():\n",
    "    # 給機器學的參數\n",
    "    # adam預設為0.001\n",
    "    learning_rate = 0.005\n",
    "    # 迭代次數(10提升準確度至98%)\n",
    "    training_iters = 10\n",
    "    # 每次樣本數\n",
    "    batch_size = 128\n",
    "\n",
    "    # 模型參數(層、步數、隱藏值、分成幾類)\n",
    "    n_input = 28\n",
    "    n_step = 28\n",
    "    n_hidden = 256\n",
    "    n_classes = 10\n",
    "\n",
    "    #讀取資料，進行資料前處理\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    x_train, x_test, y_train_o, y_test_o = lstm_preprocess(x_train, x_test, y_train, y_test, n_step, n_input, n_classes)\n",
    "\n",
    "    #訓練lstm模型並印出結果\n",
    "    model = lstm_model(n_input, n_step, n_hidden, n_classes)\n",
    "    trainning(model, x_train, y_train_o, x_test, y_test_o, learning_rate, training_iters, batch_size)\n",
    "    scores = model.evaluate(x_test, y_test_o, verbose=0)\n",
    "    print('LSTM test accuracy:', scores[1])\n",
    "    print_confusion_result(x_train, x_test, y_train, y_test, model)\n",
    "\n",
    "def mnist_cnn_main():\n",
    "    # 給機器學的參數\n",
    "    learning_rate = 0.001\n",
    "    training_iters = 1\n",
    "    batch_size = 64\n",
    "\n",
    "    #讀取資料，進行資料前處理\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    x_train, x_test, y_train_o, y_test_o = cnn_preprocess(x_train, x_test, y_train, y_test)\n",
    "\n",
    "    #訓練cnn模型並印出結果\n",
    "    model = cnn_model()\n",
    "    trainning(model, x_train, y_train_o, x_test, y_test_o, learning_rate, training_iters, batch_size)\n",
    "    scores = model.evaluate(x_test, y_test_o, verbose=0)\n",
    "    print('CNN test accuracy:', scores[1])\n",
    "    print_confusion_result(x_train, x_test, y_train, y_test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 256)               291840    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 294,410\n",
      "Trainable params: 294,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "469/469 [==============================] - 40s 78ms/step - loss: 0.7147 - accuracy: 0.7544 - val_loss: 0.0865 - val_accuracy: 0.9734\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 38s 81ms/step - loss: 0.0957 - accuracy: 0.9722 - val_loss: 0.0639 - val_accuracy: 0.9811\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 38s 81ms/step - loss: 0.0613 - accuracy: 0.9818 - val_loss: 0.0527 - val_accuracy: 0.9832\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 38s 82ms/step - loss: 0.0483 - accuracy: 0.9855 - val_loss: 0.0529 - val_accuracy: 0.9851\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 39s 83ms/step - loss: 0.0359 - accuracy: 0.9888 - val_loss: 0.0422 - val_accuracy: 0.9871\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 39s 84ms/step - loss: 0.0344 - accuracy: 0.9894 - val_loss: 0.0427 - val_accuracy: 0.9864\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 38s 82ms/step - loss: 0.0250 - accuracy: 0.9923 - val_loss: 0.0386 - val_accuracy: 0.9890\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 39s 83ms/step - loss: 0.0253 - accuracy: 0.9920 - val_loss: 0.0399 - val_accuracy: 0.9874\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 38s 82ms/step - loss: 0.0214 - accuracy: 0.9932 - val_loss: 0.0431 - val_accuracy: 0.9883\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 38s 82ms/step - loss: 0.0202 - accuracy: 0.9941 - val_loss: 0.0603 - val_accuracy: 0.9835\n",
      "LSTM test accuracy: 0.9835000038146973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ben82\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5915    0    0    0    1    1    3    0    0    3]\n",
      " [   0 6738    1    0    1    0    1    0    1    0]\n",
      " [   5   15 5916    2    1    0    0    3   15    1]\n",
      " [   3    3   10 6015    0   55    0    2   35    8]\n",
      " [   0    5    0    0 5798    0    1    2    4   32]\n",
      " [   1    0    0    2    0 5410    6    0    1    1]\n",
      " [   2    2    0    0    3    2 5906    0    3    0]\n",
      " [   0   98    9    1    4    8    0 6088   10   47]\n",
      " [   3    2    0    0    0   35   11    1 5792    7]\n",
      " [   0    1    0    0    5   28    0    4    4 5907]] \n",
      "\n",
      " [[ 975    0    0    0    0    2    1    0    0    2]\n",
      " [   1 1131    1    0    0    1    1    0    0    0]\n",
      " [   0    9 1014    0    1    0    1    1    6    0]\n",
      " [   0    0    2  994    0    9    0    1    3    1]\n",
      " [   0    1    0    0  965    0    0    1    1   14]\n",
      " [   1    0    0    1    0  889    1    0    0    0]\n",
      " [   3    2    1    0    1    5  945    0    0    1]\n",
      " [   0   26    8    1    0    2    0  974    6   11]\n",
      " [   2    1    0    0    0    6    2    0  959    4]\n",
      " [   0    1    0    0    3    5    0    3    8  989]]\n"
     ]
    }
   ],
   "source": [
    "mnist_lstm_main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 10, 10, 48)        38448     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 48)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1200)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               307456    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 84)                21588     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 369,174\n",
      "Trainable params: 369,174\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "938/938 [==============================] - 36s 38ms/step - loss: 0.3433 - accuracy: 0.8990 - val_loss: 0.0555 - val_accuracy: 0.9815\n",
      "CNN test accuracy: 0.9815000295639038\n",
      "[[5784    1    0    2    1    2  119    0   11    3]\n",
      " [   1 6642   22    3    5    0   22   18   29    0]\n",
      " [   7    3 5848   17    4    0   21   17   38    3]\n",
      " [   0    0   15 6046    0    3    1    5   55    6]\n",
      " [   1    6    2    0 5759    0   58    2    5    9]\n",
      " [   1    1    1   50    0 5215   50    0  101    2]\n",
      " [   1    0    0    0    2    0 5903    0   12    0]\n",
      " [  13   10   28   15   16    3    1 6133    7   39]\n",
      " [   2    2    1    2    2    3    8    3 5820    8]\n",
      " [  11    4    0   17   67    9    3   13   59 5766]] \n",
      "\n",
      " [[ 964    0    0    0    0    0   12    1    3    0]\n",
      " [   0 1116    1    1    0    0    9    1    7    0]\n",
      " [   4    1 1013    0    1    0    4    2    7    0]\n",
      " [   0    0    2  999    0    1    0    0    7    1]\n",
      " [   1    0    0    0  966    0   10    1    2    2]\n",
      " [   1    0    0   15    0  860    6    0   10    0]\n",
      " [   0    1    0    0    1    1  954    0    1    0]\n",
      " [   0    3    8    3    0    0    0 1007    1    6]\n",
      " [   0    0    0    0    0    0    2    1  969    2]\n",
      " [   2    4    0    4   10    2    2    3   15  967]]\n"
     ]
    }
   ],
   "source": [
    "mnist_cnn_main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
